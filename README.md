<h1 align="center">Pr√°ctica 1</h1>

<h2 align="center">Asignatura: Visi√≥n por Computador</h2>

Universidad de Las Palmas de Gran Canaria  
Escuela de Ingenier√≠a en Inform√°tica  
Grado de Ingenier√≠a Inform√°tica  
Curso 2025/2026 

<h2 align="center">Autores</h2>

- Asmae Ez Zaim Driouch
- Javier Castilla Moreno

<h2 align="center">Bibliotecas utilizadas</h2>

[![NumPy](https://img.shields.io/badge/NumPy-%23013243?style=for-the-badge&logo=numpy)](https://numpy.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-%23FD8C00?style=for-the-badge&logo=opencv)](https://opencv.org/)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-%43FF6400?style=for-the-badge&logo=matplotlib&logoColor=white)](https://matplotlib.org/)

## C√≥mo usar
### Primer paso: clonar este repositorio
```bash
git clone "https://github.com/Javier-Castilla/VC-P1"
```
### Segundo paso: Activar tu envinroment e instalar dependencias
> [!NOTE]
> Todas las dependencias pueden verse en [este archivo](envinronment.yml). Si se desea, puede crearse un entorno de Conda con dicho archivo.

Si se opta por crear un nuevo `Conda envinronment` a partir del archivo expuesto, es necesario abrir el `Anaconda Prompt` y ejecutar lo siguiente:

```bash
conda env create -f environment.yml
```

Posteriormente, se activa el entorno:

```bash
conda activate VC_P1
```

### Tercer paso: ejecutar el cuaderno
Finalmente, abriendo nuestro IDE favorito y teniendo instalado todo lo necesario para poder ejecutar notebooks, se puede ejecutar el cuaderno de la pr√°ctica [Pr√°ctica1.ipynb](Pr√°ctica1.ipynb) seleccionando el envinronment anteriormente creado.

> [!IMPORTANT]
> Todos los bloques de c√≥digo deben ejecutarse en √≥rden, de lo contrario, podr√≠a ocasionar problemas durante la ejecuci√≥n del cuaderno.

<h1 align="center">Tareas</h2>


<h2 align="center">Tarea 1: Tablero de ajedrez</h2>

Se genera tableros de ajedrez utilizando OpenCV y NumPy. El c√≥digo crea diferentes variaciones de tableros con patrones alternados de colores y diferentes dimensiones. El c√≥digo produce tres versiones:

- Versi√≥n cl√°sica: Blanco y negro tradicional
- Versi√≥n colorida: Rosa y verde pastel
- Versi√≥n dimensiones aumentada: En este caso 16x16

El recorrido se realiza mediante dos bucles anidados que iteran por filas y columnas. El incremento se hace por el tama√±o del cuadrado para posicionarse en cada casilla:

```python
    for row in range(0, height, height//dimension):
    current_offset = int(offset) * square_size

    for column in range(0, width, width//dimension):
        
        if(((row // square_size) + (column // square_size)) & 1 == 0):
            square_color=color1
        else:
            square_color=color2

        cv2.rectangle(color_img, 
                      (row+current_offset,column),
                      (row+current_offset+square_size,column+square_size), 
                      square_color, 
                      -1)
        offset = not offset
```

El patr√≥n de ajedrez se logra usando una operaci√≥n bitwise que determina si la suma de coordenadas es par o impar:

```python
    if(((row // square_size) + (column // square_size)) & 1 == 0):
            square_color=color1
        else:
            square_color=color2

```

El operador & 1 obtiene el bit menos significativo
Si es 0 ‚Üí n√∫mero par ‚Üí primer color
Si es 1 ‚Üí n√∫mero impar ‚Üí segundo color

Se define el tama√±o de cada cuadrado dividiendo las dimensiones totales entre el n√∫mero de casillas por lado:
```python
    square_size = (width//dimension)
```

El offset corrige la alineaci√≥n del patr√≥n alternado:

- Se alterna entre True y False en cada fila
- Desplaza horizontalmente cada fila par para mantener el patr√≥n de ajedrez
- Evita que las filas se desalineen creando columnas verticales del mismo color

```python
    current_offset = int(offset) * square_size
    offset = not offset
```

<table align="center">
   <td width="33.33%">
      <h3 align="center">Tablero de ajedrez 8x8</h3>
      <div align="center">
      <img src="imgs/chess_8x8_B&W.jpg" width="640" height="480" alt="Tablero de ajedrez 8x8">
   </td>
   <td width="33.33%">
      <h3 align="center">Tablero de ajedrez colorido 8x8</h3>
      <div align="center">                                       
      <img src="imgs/chess_8x8_colored.jpg" width="640" height="480"  
      alt=" Tablero de ajedrez colorido 8x8"></a>
   <br> 
   <td width="50%">
      <h3 align="center">Tablero de ajedrez colorido 16x16</h3>
      <div align="center">                                       
      <img src="imgs/chess_16x16_colored.jpg" width="640" height="480"  
      alt="Tablero de ajedrez colorido 16x16"></a>
   <br>                                                 
</table>

<h2 align="center">Tarea 2: Imagen al estilo Mondrian</h2>

Se ha generado una imagen al estilo `Mondrian` haciendo uso de las utilidades que presenta la biblioteca `OpenCV`.

Concretamente, se ha tomado como referencia la siguiente imagen:

<img src="https://www.descubrirelarte.es/wp-content/uploads/2020/11/Composicion-con-amarillo-rojo-negro-azul-y-gris-por-Piet-Mondrian-1920-oleo-sobre-lienzo-595-x-595-cm-La-Haya-Gemeentemuseum..jpg">

La manera de proceder ha sido sencilla, se han guardado en una lista de python las distintas coordenadas necesarias para dibujar los distintos rect√°ngulos que conforman la imagen. Junto a las coordenadas, se establece el color que tendr√° cada rect√°ngulo.

Una vez guardadas las diferentes coordenadas y colores, se recorre la lista y se dibuja sobre una imagen generada inicialmente en blanco cada rect√°ngulo de la siguiente manera:

```python
for i, rectangle in enumerate(rectangles):
    cv2.rectangle(img, rectangle[0], rectangle[1], rectangle[2], -1)
    cv2.rectangle(img, rectangle[0], rectangle[1], (0, 0, 0), 5)
```

> [!NOTE]
> La funci√≥n `cv2.rectangle` es la encargada de dicujar cada rect√°ngulo pas√°ndole la imagen, las coordenadas de las esquinas superior izquierda e inferior derecha, su color y su ancho, siendo `-1` el valor para rellenar el rect√°ngulo

Posteriormente, se muestra la imagen y se guarda en disco de la siguiente manera:

```python
plt.imshow(img)
plt.show()
cv2.imwrite('imgs/mondrian.jpg', cv2.cvtColor(img, cv2.COLOR_RGB2BGR))
```

> [!NOTE]
> Destacar que es necesario pasar la imagen a BGR antes de guardarla en disco haciendo uso de OpenCV para una correcta visualizaci√≥n posterior. Esto seguir√° presente a lo largo de la pr√°ctica.

La imagen resultante es la siguiente:

<img src=imgs/mondrian.jpg>

<h2 align="center">Tarea 3: editar los diferentes planos de una imagen</h2>

Para esta tarea, se han editado los diferentes planos tanto de una imagen guardada en disco como los fotogramas de un v√≠deo en vivo tomados desde la webcam del ordenador.
Con el fin de que dichas modificaciones sean reutilizables y aplicables a diferentes im√°genes o fotogramas, se ha realizado una clase para esta tarea, permitiendo aplicar filtros y m√°scaras de una manera sencilla y c√≥moda (`Tarea3`).

En dicha existen m√©todos est√°ticos que permiten invertir los diferentes colores de una imagen (R, G, B) as√≠ como el negativo de la misma o en su defecto, modificar individualmente y de manera personalizada los diferentes canales. En resumen, permite las siguientes operaciones:
- Imagen en negativo
- Invertir un canal espec√≠fico
- Modificar canales de manera personalizada


<h3 align="center">Modificaci√≥n de los diferentes canales de una imagen le√≠da de disco</h3>

Para lograr esto, se ha seleccionado una imagen y se ha cargado en memoria desde el disco con el siguiente c√≥digo:

```python
image = cv2.imread('imgs/happy_hamster.jpg', cv2.IMREAD_COLOR_RGB)
plt.imshow(image)
plt.show()
```

Mostr√°ndose la siguiente imagen:

<img src="imgs/happy_hamster.jpg" width=800 height=800>

> [!NOTE]
> La funci√≥n `cv2.imread` es la encargada de leer la imagen de disco pasadas una ruta y la forma de lectura, que en este caso ha sido lectura en `RGB`, pues originalmente `OpenCV` lee las im√°genes en `BGR`.

A continuaci√≥n, se han invertido los colores de la imagen haciendo uso de la clase `Tarea3` nombrada anteriormente.

Se presenta el c√≥digo de dicho m√©todo:

```python
@staticmethod
def negative_image(image):
    return 255 - image
```

Simplemente, se resta al `valor m√°ximo (255)` el valor de cada p√≠xel de la imagen, obteniendo as√≠ su complementario. El resultado se muestra con el siguiente c√≥digo:

```python
plt.imshow(img := Tarea3.apply(image, Tarea3.NEGATIVE))
plt.show()
cv2.imwrite("imgs/happy_hamster_negative.jpg", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))
```

Y √©sta es la imagen resultante:

<img src="imgs/happy_hamster_negative.jpg">

Aplicando √©sta misma estrategia, se ha invertido el canal `verde (G)` de la imagen original, resultando en el siguiente c√≥digo:

```python
plt.imshow(img := Tarea3.apply(image, Tarea3.INVERT_GREEN))
plt.show()
cv2.imwrite("imgs/happy_hamster_green_negative.jpg", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))
```

Resultando en la siguiente imagen:

<img src="imgs/happy_hamster_green_negative.jpg">

El m√©todo utilizado para ello ha sido el siguiente:

```python
@staticmethod
def invert_green(image):
    image = image.copy()
    image[:,:,1] = 255 - image[:,:,1]
    return image
```

En √©l, se observa como se aplica la misma estrategia inicial, pues se le resta al `m√±aximo valor (255)` el valor de cada p√≠xel en el `canal verde (G)`.

> [!NOTE]
> Para invertir el resto de colores se aplica la misma estrategia en el `canal deseado`.

Finalmente, se ha editado de manera aleatoria la imagen original, `invirtiendo el canal rojo (R)`, estableciendo al `12% de su valor original el canal verde (G)` y `omitiendo completamente el canal azul (B)`. Para ello se ha hecho uso del siguiente c√≥digo:

```python
plt.imshow(img := Tarea3.change_color_percentage(image, -1, 0.12, 0))
plt.show()
cv2.imwrite("imgs/happy_hamster_random.jpg", cv2.cvtColor(img, cv2.COLOR_RGB2BGR))
```

Resultando en la siguiente imagen:

<img src="imgs/happy_hamster_random.jpg">

Para lograr esto, se ha hecho uso del siguiente m√©todo:

```python
@staticmethod
def change_color_percentage(image, r=1, g=1, b=1):
    image = image.copy()
    image[:,:,0] = (image[:,:,0] * r) if r != -1 else 255 - image[:,:,0]
    image[:,:,1] = (image[:,:,1] * g) if g != -1 else 255 - image[:,:,1]
    image[:,:,2] = (image[:,:,2] * b)if b != -1 else 255 - image[:,:,2]
    return image
```

Como se puede observar, se pasan por par√°metros tanto la `imagen` como el `porcentaje del valor` que tendr√° cada canal en la nueva imagen, `siendo -1 la inversi√≥n de dicho canal`.

<h3 align="center">Modificaci√≥n de los diferentes canales de los fotogramas de un v√≠deo en vivo tomado desde la webcam</h3>

Para lograr obtener un v√≠deo en vivo a trav√©s de la webcam, al igual que para leer una imagen de disco, se ha usado la biblioteca `OpenCV`, concretamente el siguiente m√©todo:

```python
video = cv2.VideoCapture(0)
```

√âsto, con la ayuda de un bucle infinito, permite leer los diferentes fotogramas del v√≠deo en tiempo real tomado por la webcam de la siguiente manera:

```python
while True:
    ret, frame = video.read()
```

> [!NOTE]
> En la variable `ret`se indica si se ha le√≠do un fotograma, mientras que en `frame` se guarda el fotograma en caso de ser le√≠do correctamente.

En este caso, se han a√±adido controles para cambiar entre la inversi√≥n total de canales de los fotogramas o en consecuencia, la inversi√≥n de un canal concreto. Los controles son los siguientes:
- `1` -> Negativo
- `2` -> Verde invertido
- `3` -> Azul invertido
- `4` -> Rojo invertido

Al elegir la m√°scara que queramos aplicar a la imagen, se mostrar√° en tiempo real, permiti√©ndo ver el v√≠deo tomado por la webcam de maneras singulares.

A continuaci√≥n, se muestra una tabla con las cuatro modificaciones posibles:

<table align"center>
    <td width="25%">
        <img src="imgs/video_negative.jpg">
    </td>
    <td width="25%">
        <img src="imgs/video_red_negative.jpg">
    </td>
    <td width="25%">
        <img src="imgs/video_green_negative.jpg">
    </td>
    <td width="25%">
        <img src="imgs/video_blue_negative.jpg">
    </td>
</table>

Para la definici√≥n de los controles, se ha usado el siguiente fragmento de c√≥digo:

```python
pressed_key = cv2.waitKey(20) & 0xFF

if pressed_key == 27:
    break
elif pressed_key in methods_map:
    current_method = methods_map[pressed_key]
```

En el c√≥digo anterior, 27 es el valor `ASCII` asignado a la tecla `ESC`. Si se ha detectado esta tecla, se termina la ejecuci√≥n. Encambio, si se ha detectado cualquier tecla del `1 al 4`, se aplica al fotograma la modificaci√≥n de canales correspondiente.

> [!NOTE]
> Para la modificaci√≥n de los diferentes canales de cada fotograma, se ha seguido el mismo procedimiento que con la imagen le√≠da de disco, es decir, se ha hecho uso de las utilidades desarrolladas en la clase `Tarea3`.

<h2 align="center">Tarea 4a: Enconcontrar p√≠xel m√°s claro y oscuro de la imagen</h2>

Para esta tarea se desarrolla dos versiones de un sistema de detecci√≥n en tiempo real que identifica autom√°ticamente los p√≠xeles m√°s claros y oscuros de una imagen capturada desde la webcam utilizando OpenCV. El programa marca visualmente estos p√≠xeles y muestra sus valores de intensidad.Las versiones desarrolladas son:

- Usando cv2.minMaxLoc()
- Usando las herramientas de numpy

<h3 align="center">Tarea 4a: Usando cv2.minMaxLoc()</h3>

Se utiliza la funci√≥n nativa de OpenCV para encontrar eficientemente los valores m√≠nimos y m√°ximos en una imagen en escala de grises:

```python
    def find_max_and_min_pixel(frame):
    gray_vid = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    return cv2.minMaxLoc(gray_vid)
```

Convierte la imagen a escala de grises para an√°lisis de intensidad y retorna una tupla:
- `min_val`: Valor del p√≠xel m√°s oscuro (0-255)
- `max_val`: Valor del p√≠xel m√°s claro (0-255)  
- `min_loc`: Coordenadas (x,y) del p√≠xel m√°s oscuro
- `max_loc`: Coordenadas (x,y) del p√≠xel m√°s claro

üìö **Documentaci√≥n oficial:** [cv2.minMaxLoc() - OpenCV Documentation](https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga7622c466c628a75d9ed008b42250a73f)


Bucle Principal de procesamiento:

```python
    while(True):
    ret, frame = vid.read()

    if ret:

        if (mouse_event_flag==0):
            cv2.imshow("Camara", frame)
            cv2.setMouseCallback("Camara", mouse_events)
            mouse_event_flag=1

        min_px, max_px, min_px_coordinates, max_px_coordinates = find_max_and_min_pixel(frame)

        cv2.circle(frame, min_px_coordinates, 10, min_color, 2)
        cv2.circle(frame, max_px_coordinates, 10, max_color, 2)

        # Se usa la funci√≥n creada para que el texto no salga de la imagen
        put_text_inside(frame, f"Darker: {min_px}", min_px_coordinates, 
                        font=cv2.FONT_HERSHEY_TRIPLEX, scale=0.5, color=min_color, thickness=1)

        put_text_inside(frame, f"Lighter: {max_px}", max_px_coordinates, 
                        font=cv2.FONT_HERSHEY_TRIPLEX, scale=0.5, color=max_color, thickness=1)
        
        cv2.imshow('Camara', frame)
```

Procesa cont√≠nuamente los frames del v√≠deo y al obtener los valores de intensidad los marca con c√≠rculo de colores y un texto con su informaci√≥n num√©rica que siempre permanece visible:
- **P√∫rpura** `(100,0,100)` ‚Üí P√≠xel m√°s oscuro
- **Rosa** `(50,0,200)` ‚Üí P√≠xel m√°s claro

**Salida del Programa**:
Pulsando en **ESC** se termina la ejecuci√≥n y cierra la aplicaci√≥n

<img src="imgs\px_mas_oscuro_claro.png" width=800 height=800>


<h3 align="center">Tarea 4a: Usando las herramientas de numpy</h3>

Otra manera de realizar esta tarea es utilizando los m√©todos que nos brinda `numpy`, pues √©sta biblioteca almacena los valores de la imagen de forma lineal, y dado que est√° desarrollada en `C`, los m√©todos que tiene para buscar valores m√°ximos y m√≠nimos son realmente eficientes y r√°pidos. Concretamente, se han desarrollado estas funciones para encontrar el p√≠xel m√°s oscuro y m√°s claro respectivamente con ayuda de `numpy`:

```python
def darkest_pixel_index(image):
    y, x, *_ = np.unravel_index(np.argmin(image), image.shape)
    return (x, y)
```

```python
def lightest_pixel_index(image):
    y, x, *_ = np.unravel_index(np.argmax(image), image.shape)
    return (x, y)
```

> [!NOTE]
> Los m√©todos `np.argmin` y `np.argmax` devuelven el √≠ndice lineal con el `valor m√≠nimo (p√≠xel m√°s oscuro)` y `maximo (p√≠xel m√°s claro)` respectivamente. Sin embargo, es necesario obtener las coordenadas de dichos p√≠xeles, por lo que `numpy` cuanta con el m√©todo `np.unravel_index`. que nos har√°n la traspolaci√≥n.

A continuaci√≥n, se ha cargado la misma imagen de la `Tarea 3` para detectar en ella el p√≠xel m√°s claro y m√°s oscuro:

```python
image = cv2.imread("imgs/happy_hamster.jpg", cv2.IMREAD_COLOR_RGB)
gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
```

> [!NOTE]
> N√≥tese el cambio de la imagen a escala de grises para facilitar la detecci√≥n de dichos p√≠xeles.

Una vez cargada la imagen, se consiguen las coordenadas de ambos p√≠xeles comn las funciones mostradas anteriormente y se dibujan en la misma dichos p√≠xeles unidos por una l√≠nea, as√≠ como se indica el valor `RGB` de dichos p√≠xeles:

```python
min_index = darkest_pixel_index(gray)
max_index = lightest_pixel_index(gray)

val_max = image[max_index[1], max_index[0]].copy()
val_min = image[min_index[1], min_index[0]].copy()

cv2.circle(image, min_index, 5, (255, 255, 255), -1)
cv2.circle(image, max_index, 5, (0, 0, 0), -1)
cv2.line(image, min_index, max_index, (0, 255, 150))

put_text_inside(image, str(val_max), max_index)
put_text_inside(image, str(val_min), min_index)
```

Resultando en la siguiente imagen:

<img src="imgs/happy_hamster_pixels.jpg">

> [!NOTE]
> Si se quisiera usar para detectar dichos p√≠xeles entiempo real en un v√≠deo tomado con la webcam, bastar√≠a con usar las funciones presentadas anteriormente en cada fotograma.

Para ambas versiones se ha detectado que usando el cv2.putText(), cuando el pixel m√°s oscuro o m√°s claro se encuentra en los bordes de la imagen, el texto se muestra fuera de la misma. Por ello se ha utilizado herramientas de IA para generar una funci√≥n que evite que las etiquetas de texto se salgan de los l√≠mites de la imagen ajustando autom√°ticamente su posici√≥n:

```python
    def put_text_inside(
    img,
    text,
    pos,
    font=cv2.FONT_HERSHEY_SIMPLEX,
    scale=0.6,
    color=(0,0,0),
    thickness=1,
    offset=(10, -10)
):
    """
    Dibuja un texto dentro de los l√≠mites de la imagen, con un peque√±o offset respecto a la posici√≥n dada.
    Par√°metros:
        img   : imagen destino
        text  : string a dibujar
        pos   : (x, y) coordenadas del punto de referencia
        offset: (dx, dy) desplazamiento respecto a pos
    """
    h, w = img.shape[:2]
    (text_w, text_h), _ = cv2.getTextSize(text, font, scale, thickness)

    # Aplicar offset
    x = pos[0] + offset[0]
    y = pos[1] + offset[1]

    # Ajustar coordenadas si el texto se sale
    if x < 0:
        x = 0
    if x + text_w > w:
        x = w - text_w
    if y - text_h < 0:
        y = text_h
    if y > h - 1:
        y = h - 1

    cv2.putText(img, text, (x, y), font, scale, color, thickness, cv2.LINE_AA)
```

<h2 align="center">Tarea 4b: Enconcontrar la zona 8x8 m√°s clara/oscuran</h2>

Para esta tarea se desarrolla tres versiones de un sistema de detecci√≥n en tiempo real que identifica regiones completas seg√∫n las dimensiones propuestas (en un inicio 8x8) m√°s claros y oscuros de una imagen capturada desde la webcam utilizando OpenCV.Las versiones desarrolladas son:

- Usando cv2.resize()
- Usando m√°scaras
- Usando Fuerza bruta

Nuevamente, en las tres versiones se hace usao de la funci√≥n anterior en donde evita que las etiquetas de texto se salgan de los l√≠mites de la imagen ajustando autom√°ticamente su posici√≥n: **put_text_inside(img, text, pos, font=cv2.FONT_HERSHEY_SIMPLEX, scale=0.6, color=(0,0,0), thickness=1, offset=(10, -10))**

<h3 align="center">Tarea 4b:  Usando cv2.resize()</h3>

El algoritmo divide la imagen en una grilla de bloques de 8x8 p√≠xeles y encuentra las regiones con mayor y menor intensidad promedio. 

Esto se logra debido a que la funci√≥n resize de openCV divide mentalmente la imagen en una cuadr√≠cula de bloques 8x8 y calcula el promedio de intensidad de cada bloque usando interpolaci√≥n bilineal.


üìö **Documentaci√≥n t√©cnica:** [Resizing and Rescaling Images with OpenCV](https://opencv.org/blog/resizing-and-rescaling-images-with-opencv/)

Logrando con ello reducir el costo computacional.

```python
    def find_max_and_min_pixel_8x8(frame):
    gray_vid = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    height, width = gray_vid.shape
    vid_block = cv2.resize(gray_vid, (width//block_size, height//block_size))
    return cv2.minMaxLoc(vid_block)
```

Una imagen de 640x480 se convierte en 80x60. Con `cv2.resize()` se calcula autom√°ticamente el valor promedio de cada bloque 8x8 y se obtiene los valores resultantes representan fielmente la intensidad promedio de cada regi√≥n.

Como trabajamos con una imagen reducida, debemos escalar las coordenadas de vuelta a la resoluci√≥n original:

```python
   # Escalar coordinadas de vuelta
        min_block_coordinates_scale = ((min_block_coordinates[0]*block_size+(block_size//2)),
                                       (min_block_coordinates[1]*block_size+(block_size//2)))
        max_block_coordinates_scale = ((max_block_coordinates[0]*block_size+(block_size//2)),
                                       (max_block_coordinates[1]*block_size+(block_size//2)))

```
1. **Multiplicar por `block_size`**: Convierte coordenadas de bloque a p√≠xeles
2. **Sumar `block_size//2`**: Centra el marcador en el medio del bloque
3. **Resultado**: Coordenada del centro del bloque 8x8 en la imagen original

Finalmente se emplea marcadores circulares para representar visualmente el √°rea.

<img src="imgs\region_mas_oscura_clara.png" width=800 height=800>

<h3 align="center">Tarea 4b:  Usando m√°scaras</h3>

Otra forma de lograr esto es aplicar un `kernel` o `m√°scara` a la imagen con funciones que `OpenCV` nos brinda como puede ser `cv2.filter2D`. Para ello, primero es necesario crea el kernel de la siguiente manera:

```python
h, w, c = frame.shape
gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
gray_crop = gray[:(h//block_size)*block_size-block_size,:(w//block_size)*block_size-block_size]

kernel = np.ones((block_size, block_size), dtype=np.float32) / (block_size**2)
```

Una vez pose√≠do el `kernel`, que no es m√°s que la m√°scara a aplicar sobre la imagen, se aplica a la misma, obteniendo un promedio donde cada coordenada es el comienzo del bloque 8x8 pr√≥ximo. Esto nos ayuda a encontrar cu√°l tiene el mayor y menor promedio, es decir, el `bloque 8x8 m√°s oscuro y m√°s claro de la imagen`.

```python
avg_map = cv2.filter2D(gray_crop, -1, kernel)

min_idx = np.unravel_index(np.argmin(avg_map), avg_map.shape)
max_idx = np.unravel_index(np.argmax(avg_map), avg_map.shape)
```
Una vez obtenidos los √≠ndices estos bloques, simplement se dibujan sobre la imagen o el fotograma como se muestra a continuaci√≥n:

```python
cv2.rectangle(frame, (min_idx[1], min_idx[0]), (min_idx[1]+block_size, min_idx[0]+block_size), (0,255,0), 1)
cv2.rectangle(frame, (max_idx[1], max_idx[0]), (max_idx[1]+block_size, max_idx[0]+block_size), (0,0,255), 1)
```

<h3 align="center">Tarea 4b:  Usando Fuerza bruta</h3>

La √∫ltima forma en la que se ha procedido, ha sido realizar nosotros mismos esa m√°scara. En cierto modo, se trata de una `ventana deslizante` que se ha ido moviendo por toda la imagen encontrando el mayor y menor promedio de la misma. Tras finalizar el recorrido, se obtienen las coordenadas de ambos bloques para posteriormente, dibujarlos en la imagen o fotograma del v√≠deo:

```python
h, w, c = frame.shape

    current_max = float('-inf')
    current_min = float('inf')
    max_coords = None
    min_coords = None

    for y in range(0, h - 8, 8):
        for x in range(0, w - 8, 8):
            block = frame[y:y+8, x:x+8]
            value = np.mean(block)

            if value > current_max:
                current_max = value
                max_coords = (x, y)

            if value < current_min:
                current_min = value
                min_coords = (x, y)

    if min_coords:
        cv2.rectangle(frame, min_coords, (min_coords[0]+8, min_coords[1]+8), (0,255,0), 2)
    if max_coords:
        cv2.rectangle(frame, max_coords, (max_coords[0]+8, max_coords[1]+8), (0,0,255), 2)
```

> [!NOTE]
> En los tres casos presentados anteriormente, el resultado es el mismo. La √∫nica diferencia es la rapidez con la que se realizan estas b√∫squedas.

<h2 align="center">Tarea 5: Pop art</h2>

Se desarrolla un generador de arte pop digital inspirado en los estilos de **Roy Lichtenstein y Andy Warhol**. El sistema transforma fotograf√≠as convencionales en composiciones art√≠sticas mediante manipulaci√≥n del espacio de color HSV y la adici√≥n de malla de c√≠rculos para acercarnos m√°s a las caracter√≠sticos del c√≥mic.

La conversi√≥n a espacio de color HSV:

- **H (Hue):** Tono/matiz del color
- **S (Saturation)**: Saturaci√≥n/intensidad
- **V (Value)**: Brillo/luminosidad

Se inicia convirtiendo la imagen de RGB a HSV para su manipulaci√≥n:

```python
    # Convertir a HSV
    hsv = cv2.cvtColor(pop_art_rgb, cv2.COLOR_BGR2HSV)
```

A continuaci√≥n se crea la funci√≥n de desplazamiento de matiz con la que se crea variaciones crom√°ticas rotando el canal Hue de la imagen:

```python
    def shift_hue(hsv_img, shift):
    hsv_copy = hsv_img.copy()
    hsv_copy[:, :, 0] = (hsv_copy[:, :, 0].astype(int) + shift) % 180
    return hsv_copy
```

En OpenCV, el canal Hue va de 0-179 (180 valores). El operador % 180 crea un ciclo crom√°tico: 179+1 = 0 permite rotaci√≥n completa del espectro de colores sin valores fuera de rango.

Se crean 9 variaciones con diferentes desplazamientos de matiz inspirados en el estilo de Warhol:

```python
    variaciones = [0, 30, 60, 90, 10, 100, 15, 150, 45]

    imgs = [cv2.cvtColor(shift_hue(hsv, shift), cv2.COLOR_HSV2RGB) 
        for shift in variaciones]
```
0¬∞: Imagen original (referencia)
30¬∞, 60¬∞, 90¬∞: Rotaciones primarias del espectro
10¬∞, 15¬∞, 45¬∞: Variaciones sutiles para transiciones suaves
100¬∞, 150¬∞: Contrastes dram√°ticos estilo Warho

Para la salida de las im√°genes se emplea:

```python
    # Cuadr√≠cula 3x3 caracter√≠stica del arte pop
    fig, axs = plt.subplots(3, 3, figsize=(8, 8))
    for ax, im in zip(axs.ravel(), imgs):
        ax.imshow(im)
        ax.axis("off")  # Sin ejes para efecto galer√≠a
```


<table align="center">
   <td width="33.33%">
      <h3 align="center">Imagen Original</h3>
      <div align="center">
      <img src="imgs\pop_art_original_photo.jpg" width="640" height="480" alt="Tablero de ajedrez 8x8">
   </td>
   <td width="33.33%">
      <h3 align="center">Pop Art aplicado</h3>
      <div align="center">                                       
      <img src="imgs\pop_art_applied.jpg" width="640" height="480"  
      alt=" Tablero de ajedrez colorido 8x8"></a>
   <br> 
   <td width="50%">
      <h3 align="center">Pop art y efecto comic(malla circulos)</h3>
      <div align="center">                                       
      <img src="imgs\pop_art_applied_with_circles.jpg" width="640" height="480"  
      alt="Tablero de ajedrez colorido 16x16"></a>
   <br>                                                 
</table>

<h2 align="center">Bibliograf√≠a</h2>

- [Repositorio base y enunciado de √©sta pr√°ctica](https://github.com/otsedom/otsedom.github.io/tree/main/VC/P1)
- [cv2.minMaxLoc() - OpenCV Documentation](https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga7622c466c628a75d9ed008b42250a73f)
- [Resizing and Rescaling Images with OpenCV](https://opencv.org/blog/resizing-and-rescaling-images-with-opencv/)
- [Numpy sorting and searching Documentation](https://numpy.org/doc/2.1/reference/routines.sort.html)
- [Numpy indexes](https://numpy.org/doc/2.1/reference/routines.indexing.html)
- [OpenCV Filter2D](https://www.geeksforgeeks.org/python/python-opencv-filter2d-function/)